{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS 484 Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBmTSoSjMpWc"
      },
      "source": [
        "Plan:\n",
        "1. read some more papers and find all the datasets\n",
        "  a) we can use resnet50 as encoder, and then I think we build a more complicated decoder\n",
        "2. try to see if we can get an overfitted model to work\n",
        "3. try to see if we can extend that model\n",
        "4. Great Success\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstract\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPBWtNlMUKKs"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numbers\n",
        "import platform\n",
        "import copy\n",
        "\n",
        "# Importing essential libraries for basic image manipulations.\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# We import some of the main PyTorch and TorchVision libraries.\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as tF\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uO4sohTKIi8"
      },
      "outputs": [],
      "source": [
        "### model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstructing the image from the disparity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#no idea\n",
        "def reconStruct(im, dmap):\n",
        "    return im"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "source of loss function:\n",
        "from paper\n",
        "\n",
        "Difficulties with loss function:\n",
        "- keeping the loss function only with tensor operations to keep the .backward() functionality valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "# from pytorch_ssim import SSIM  \n",
        "from ignite.metrics import SSIM\n",
        "\n",
        "def gradient_x(img):\n",
        "    return img[:, :, :, :-1] - img[:, :, :, 1:]\n",
        "\n",
        "def gradient_y(img):\n",
        "    return img[:, :, :-1, :] - img[:, :, 1:, :]\n",
        "\n",
        "\n",
        "def appearance_loss(img, recon, alpha):\n",
        "    l1 = torch.abs(img - recon)\n",
        "    ssim_loss = SSIM(img, recon)\n",
        "    return (alpha * ssim_loss.mean()) + ((1 - alpha) * l1.mean())\n",
        "\n",
        "def disparity_smoothness(disp, img):\n",
        "    disp_grad_x = gradient_x(disp)\n",
        "    disp_grad_y = gradient_y(disp)\n",
        "    img_grad_x = gradient_x(img)\n",
        "    img_grad_y = gradient_y(img)\n",
        "\n",
        "    weights_x = torch.exp(-torch.mean(torch.abs(img_grad_x), 1, keepdim=True))\n",
        "    weights_y = torch.exp(-torch.mean(torch.abs(img_grad_y), 1, keepdim=True))\n",
        "\n",
        "    smoothness_x = disp_grad_x * weights_x\n",
        "    smoothness_y = disp_grad_y * weights_y\n",
        "\n",
        "    return smoothness_x.abs().mean() + smoothness_y.abs().mean()\n",
        "\n",
        "def lr_consistency_loss(disp_left, disp_right):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        disp_left:  [B, 1, H, W] disparity map from left view (predicts right image)\n",
        "        disp_right: [B, 1, H, W] disparity map from right view (predicts left image)\n",
        "\n",
        "    Returns:\n",
        "        Scalar tensor representing left-right consistency loss.\n",
        "    \"\"\"\n",
        "    B, _, H, W = disp_left.shape\n",
        "\n",
        "    # Create normalized horizontal coordinate grid\n",
        "    grid_x = torch.linspace(-1.0, 1.0, W).view(1, 1, 1, W).expand(B, 1, H, W).to(disp_left.device)\n",
        "    grid_y = torch.linspace(-1.0, 1.0, H).view(1, 1, H, 1).expand(B, 1, H, W).to(disp_left.device)\n",
        "\n",
        "    # Normalize disparity to [-1, 1] range\n",
        "    disp_left_norm = disp_left / ((W - 1) / 2)\n",
        "    disp_right_norm = disp_right / ((W - 1) / 2)\n",
        "\n",
        "    # Sample right disparity using left disparity to warp\n",
        "    grid_warped_right = torch.cat([grid_x - disp_left_norm, grid_y], dim=1)\n",
        "    grid_warped_right = grid_warped_right.permute(0, 2, 3, 1)  # [B, H, W, 2]\n",
        "    sampled_right = F.grid_sample(disp_right, grid_warped_right, mode='bilinear', padding_mode='border', align_corners=True)\n",
        "\n",
        "    # Sample left disparity using right disparity to warp\n",
        "    grid_warped_left = torch.cat([grid_x + disp_right_norm, grid_y], dim=1)\n",
        "    grid_warped_left = grid_warped_left.permute(0, 2, 3, 1)\n",
        "    sampled_left = F.grid_sample(disp_left, grid_warped_left, mode='bilinear', padding_mode='border', align_corners=True)\n",
        "\n",
        "    # L1 loss between disparity and its warped counterpart\n",
        "    loss_left = torch.abs(disp_left - sampled_right).mean()\n",
        "    loss_right = torch.abs(disp_right - sampled_left).mean()\n",
        "\n",
        "    return loss_left + loss_right\n",
        "\n",
        "\n",
        "def custom_loss(imL, imR, dL, dR, recImL, recImR, alpha=0.85, alpha_ap=1.0, alpha_ds=0.1, alpha_lr=1.0):\n",
        "\n",
        "    loss_ap = appearance_loss(imL, recImL, alpha) + appearance_loss(imR, recImR, alpha)\n",
        "\n",
        "    loss_ds = disparity_smoothness(dL, imL) + disparity_smoothness(dR, imR)\n",
        "\n",
        "    loss_lr = lr_consistency_loss(dL, dR)\n",
        "    # --- Total Loss ---\n",
        "    total_loss = alpha_ap * loss_ap + alpha_ds * loss_ds + alpha_lr * loss_lr\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def SSIM(self, x, y):\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    mu_x = slim.avg_pool2d(x, 3, 1, 'VALID')\n",
        "    mu_y = slim.avg_pool2d(y, 3, 1, 'VALID')\n",
        "\n",
        "    sigma_x  = slim.avg_pool2d(x ** 2, 3, 1, 'VALID') - mu_x ** 2\n",
        "    sigma_y  = slim.avg_pool2d(y ** 2, 3, 1, 'VALID') - mu_y ** 2\n",
        "    sigma_xy = slim.avg_pool2d(x * y , 3, 1, 'VALID') - mu_x * mu_y\n",
        "\n",
        "    SSIM_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
        "    SSIM_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
        "\n",
        "    SSIM = SSIM_n / SSIM_d\n",
        "\n",
        "    return tF.clip_by_value((1 - SSIM) / 2, 0, 1)\n",
        "# def appMatchLoss(im, recIm):\n",
        "\n",
        "\n",
        "# def custom_loss(imL, imR, dl, dr, recImL, recImR):\n",
        "\n",
        "\n",
        "my_loss_function = lambda x : 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# validate the output disparity map against the ground truth\n",
        "def validateAgainstGroundTruthSingle(dl, gt):\n",
        "    #idk how im going to do this yet, will need to figure out dimensions and shit\n",
        "    return 0.5\n",
        "\n",
        "def validateAgainstGroundTruth(val_loader, net):\n",
        "    net = net.cuda()\n",
        "    ttlDiff = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "\n",
        "            imL, imR, gtDl, gtDr = data\n",
        "            # if USE_GPU:\n",
        "            imL, imR, gtDl, gtDr = imL.cuda(), imR.cuda(), gtDl.cuda(), gtDr.cuda()\n",
        "\n",
        "            dL, dR = net.forward(imL)\n",
        "            ttlDiff += validateAgainstGroundTruthSingle(dL, gtDl) + validateAgainstGroundTruthSingle(dR, gtDr)\n",
        "    \n",
        "    return ttlDiff/(2*len(val_loader))\n",
        "\n",
        "\n",
        "\n",
        "def validate(val_loader, net, loss_function = custom_loss):\n",
        "\n",
        "    net.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    # if USE_GPU:\n",
        "    net = net.cuda()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "\n",
        "            imL, imR, gtDl, gtDr = data\n",
        "            # if USE_GPU:\n",
        "            imL, imR, gtDl, gtDr = imL.cuda(), imR.cuda(), gtDl.cuda(), gtDr.cuda()\n",
        "\n",
        "\n",
        "            dL, dR = net.forward(imL)\n",
        "            val_loss += loss_function(imL, imR, dL, dR, reconStruct(imL, dR, True), reconStruct(imR, dL, False)).item()\n",
        "\n",
        "    # return the values of loss and mIOU (averaged over the loaded data)\n",
        "    return val_loss/len(val_loader.dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_loader, net, optimizer, loss_graph, loss_function = custom_loss):\n",
        "\n",
        "    net.train()\n",
        "    # if USE_GPU:\n",
        "    net = net.cuda()\n",
        "    val_loss = 0\n",
        "    for i, data in enumerate(train_loader):\n",
        "\n",
        "        imL, imR, gtDl, gtDr = data\n",
        "        # if USE_GPU:\n",
        "        imL, imR, gtDl, gtDr = imL.cuda(), imR.cuda(), gtDl.cuda(), gtDr.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        dL, dR = net.forward(imL)\n",
        "        main_loss = loss_function(imL, imR, dL, dR, reconStruct(imL, dR, True), reconStruct(imR, dL, False)).item()\n",
        "        loss = main_loss.item()\n",
        "        val_loss += loss\n",
        "        loss_graph.append(loss)\n",
        "        main_loss.backward()\n",
        "        optimizer.step()\n",
        "        # loss_graph.append() Populate this list to graph the loss\n",
        "\n",
        "    # Return the value of loss (averaged over the loaded data)\n",
        "    return val_loss/len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we are going to train an overfit net to a single image to get a sanity check that the error function and model are working as intended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_net(loader, net, optimizer, EPOCH):\n",
        "    net.train()\n",
        "\n",
        "    print(\"Starting Training...\")\n",
        "\n",
        "    loss_graph = []\n",
        "\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    plt.subplots_adjust(bottom=0.2,right=0.85,top=0.95)\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "    for e in range(EPOCH):\n",
        "        loss = train(loader, net, optimizer, loss_graph)\n",
        "        ax.clear()\n",
        "        ax.set_xlabel('iterations')\n",
        "        ax.set_ylabel('loss value')\n",
        "        ax.set_title('Training loss curve for OVERFIT_NET')\n",
        "        ax.plot(loss_graph, label='training loss')\n",
        "        ax.legend(loc='upper right')\n",
        "        fig.canvas.draw()\n",
        "        print(\"Epoch: {} Loss: {}\".format(e, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "overfit_net = copy.deepcopy(untrained_net)\n",
        "\n",
        "EPOCH = 40\n",
        "\n",
        "optimizer = get_optimizer(overfit_net)\n",
        "\n",
        "train_net(sanity_loader, overfit_net, optimizer, EPOCH)\n",
        "\n",
        "torch.save(overfit_net.state_dict(), \"overfit_net.pth\")\n",
        "torch.save(untrained_net.state_dict(), \"untrained_net.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now for the full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "trained_net = copy.deepcopy(untrained_net)\n",
        "\n",
        "EPOCH = 10\n",
        "\n",
        "optimizer = get_optimizer(trained_net)\n",
        "\n",
        "train_net(train_loader, trained_net, optimizer, EPOCH)\n",
        "\n",
        "torch.save(trained_net.state_dict(), \"trained_net.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
