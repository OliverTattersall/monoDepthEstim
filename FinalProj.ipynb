{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS 484 Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBmTSoSjMpWc"
      },
      "source": [
        "Plan:\n",
        "1. read some more papers and find all the datasets\n",
        "  a) we can use resnet50 as encoder, and then I think we build a more complicated decoder\n",
        "2. try to see if we can get an overfitted model to work\n",
        "3. try to see if we can extend that model\n",
        "4. Great Success\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstract\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPBWtNlMUKKs"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numbers\n",
        "import platform\n",
        "import copy\n",
        "\n",
        "# Importing essential libraries for basic image manipulations.\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# We import some of the main PyTorch and TorchVision libraries.\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as tF\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uO4sohTKIi8"
      },
      "outputs": [],
      "source": [
        "### model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# The whole training on a single image (20-40 epochs) should take only a minute or two on a CPU (and a few seconds on GPU).\n",
        "# Below we create a (deep) copy of untrained_net and train it on a single training image (leading to gross overfitting).\n",
        "# Later, we will create a separate (deep) copy of untrained_net to be trained on full training dataset.\n",
        "# NOTE: Normally, one can create a new net via declaration new_net = MyNet(21). But, randomization of weights when new nets\n",
        "# are declared that way creates *different* untrained nets. This notebook compares different versions of network training.\n",
        "# For this comparison to be direct and fair, it is better to train (deep) copies of the exact same untrained_net.\n",
        "overfit_net = copy.deepcopy(untrained_net)\n",
        "\n",
        "# You can change the number of EPOCHS\n",
        "EPOCH = 40\n",
        "\n",
        "# switch to train mode (original untrained_net was set to eval mode)\n",
        "overfit_net.train()\n",
        "\n",
        "optimizer = get_optimizer(overfit_net)\n",
        "\n",
        "print(\"Starting Training...\")\n",
        "\n",
        "loss_graph = []\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "plt.subplots_adjust(bottom=0.2,right=0.85,top=0.95)\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "for e in range(EPOCH):\n",
        "    loss = train(sanity_loader, overfit_net, optimizer, loss_graph)\n",
        "    ax.clear()\n",
        "    ax.set_xlabel('iterations')\n",
        "    ax.set_ylabel('loss value')\n",
        "    ax.set_title('Training loss curve for OVERFIT_NET')\n",
        "    ax.plot(loss_graph, label='training loss')\n",
        "    ax.legend(loc='upper right')\n",
        "    fig.canvas.draw()\n",
        "    print(\"Epoch: {} Loss: {}\".format(e, loss))\n",
        "torch.save(overfit_net.state_dict(), \"overfit_net.pth\")\n",
        "torch.save(untrained_net.state_dict(), \"untrained_net.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
